{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/usr/workspace/vanover1/approx-llvm/approx')\n",
    "from approx_modules import approx\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to use /usr/tce/bin/git binary because the default git version grabbed by this subprocess is too early for the --show-superproject-working-tree flag\n",
    "REPO_ROOT = subprocess.check_output(\"/usr/tce/bin/git rev-parse --show-superproject-working-tree --show-toplevel | head -1\", shell=True).strip().decode()\n",
    "N_KERNELS = 4\n",
    "KERNEL_NAMES = [\"s1\", \"t1\", \"t2\", \"t3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_arclength(endpoint):\n",
    "    \n",
    "    # compile and run arclength instrumented with HPAC directives\n",
    "    subprocess.check_call(f\"rm -f test.h5 && source {REPO_ROOT}/scripts/activate_env.sh && make arclength-hpac && ./arclength-hpac {endpoint}\", shell=True)\n",
    "    \n",
    "    # open database\n",
    "    approxDataProfile = approx.approxApplication(\"./test.h5\")\n",
    "    \n",
    "    # get output\n",
    "    Y = approxDataProfile.getApplicationOutput()['arclength'][0]\n",
    "\n",
    "    # get aggregated kernel outputs\n",
    "    kernel_outputs = []\n",
    "    for kernel_name in KERNEL_NAMES:\n",
    "        kernel_outputs.append(approxDataProfile[kernel_name].Y().mean())\n",
    "    \n",
    "    return kernel_outputs, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neighborhood for arclength analysis\n",
    "center = np.pi\n",
    "eps = np.pi\n",
    "n_sample = 2**6\n",
    "\n",
    "# uniform sample of n_sample endpoints from the neighborhood\n",
    "XX = np.linspace(center-eps, center+eps, n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(f\"XX_{n_sample}n.npy\", \"rb\") as f:\n",
    "        kernel_outs = np.load(f)\n",
    "    with open(f\"YY_{n_sample}n.npy\", \"rb\") as f:\n",
    "        YY = np.load(f)\n",
    "        \n",
    "except FileNotFoundError:\n",
    "\n",
    "    # run arclength\n",
    "    kernel_outs = []\n",
    "    YY = []\n",
    "    for X in XX:\n",
    "        temp = run_arclength(X)\n",
    "        kernel_outs.append(temp[0])\n",
    "        YY.append(temp[1])\n",
    "    kernel_outs = np.array(kernel_outs)\n",
    "    YY = np.array(YY)\n",
    "\n",
    "    with open(f\"XX_{n_sample}n.npy\", \"wb\") as f:\n",
    "        np.save(f, kernel_outs)\n",
    "    with open(f\"YY_{n_sample}n.npy\", \"wb\") as f:\n",
    "        np.save(f, YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 51 samples.\n",
      "Score: -2.695859339632184\n",
      "Sensitivities: [('s1', 0.22741495042636725), ('t1', 0.24804540201766748), ('t2', 0.25290835124607747), ('t3', 0.27163129630988797)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/tce/packages/python/python-3.7.2/lib/python3.7/site-packages/sklearn/ensemble/base.py:158: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "split_proportion = 0.8\n",
    "split_point = int(n_sample * split_proportion)\n",
    "XX_train, XX_test = kernel_outs[:split_point], kernel_outs[split_point:]\n",
    "YY_train, YY_test = YY[:split_point], YY[split_point:]\n",
    "\n",
    "print(f\"Training with {split_point} samples.\")\n",
    "\n",
    "# analyze kernel output sensitivity\n",
    "et = ExtraTreesRegressor(n_estimators=100,\n",
    "                                    criterion=\"mse\",\n",
    "                                    max_features=int(round(XX_train.shape[1] / 3)),\n",
    "                                    max_depth=8,\n",
    "                                    min_samples_split=2,\n",
    "                                    min_samples_leaf=max(1, int(round(np.sqrt(XX_train.shape[0]) / np.sqrt(1000)))),\n",
    "                                    max_leaf_nodes=None,\n",
    "                                    #bootstrap=True,\n",
    "                                    #oob_score=True,\n",
    "                        )#random_state=1)\n",
    "\n",
    "et.fit(XX_train, YY_train)\n",
    "print(f\"Score: {et.score(XX_test, YY_test)}\")\n",
    "\n",
    "Si = [(KERNEL_NAMES[k_no], et.feature_importances_[k_no]) for k_no in range(N_KERNELS)]\n",
    "Si.sort(key = lambda x : x[1])\n",
    "print(f\"Sensitivities: {Si}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to:\n",
    "```\n",
    "=== BEGIN ADAPT REPORT ===\n",
    "15000004 total independent/intermediate variables\n",
    "1 dependent variables\n",
    "Mixed-precision recommendation:\n",
    "  Replace variable d2      max error introduced: 0.000000e+00  count: 6000000     totalerr: 0.000000e+00\n",
    "  Replace variable d1      max error introduced: 0.000000e+00  count: 1           totalerr: 0.000000e+00\n",
    "  DO NOT replace   t2      max error introduced: 8.623994e-08  count: 1000000     totalerr: 8.623994e-08\n",
    "  DO NOT replace   t1      max error introduced: 8.623994e-08  count: 1000001     totalerr: 1.724799e-07\n",
    "  DO NOT replace   h       max error introduced: 5.401810e-07  count: 1           totalerr: 7.126609e-07\n",
    "  DO NOT replace   t3      max error introduced: 9.462050e-07  count: 6000000     totalerr: 1.658866e-06\n",
    "  DO NOT replace   s1      max error introduced: 6.334703e-06  count: 1000001     totalerr: 7.993569e-06\n",
    "=== END ADAPT REPORT ===\n",
    "Arclength - SUCCESSFUL!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for shaff analysis\n",
    "rows = []\n",
    "for n in range(n_sample):\n",
    "    row = {}\n",
    "    for i, kernel_name in enumerate(KERNEL_NAMES):\n",
    "        row[kernel_name] = kernel_outs[n][i]\n",
    "    row[\"Y\"] = YY[n]\n",
    "    rows.append(row)\n",
    "df = pd.DataFrame.from_dict(rows)\n",
    "df = df[[\"Y\"] + KERNEL_NAMES]\n",
    "df.to_csv(f\"df_{split_point}n.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From 5 SHAFF analysis runs with 204 samples:\n",
    "```\n",
    "[1] \"s1\" \"t1\" \"t2\" \"t3\"\n",
    "[1] 0.2657836 0.2437431 0.2235744 0.2669184\n",
    "[1] 0.2193727 0.2534944 0.2608640 0.2662938\n",
    "[1] 0.2128173 0.2503306 0.2611730 0.2756917\n",
    "[1] 0.2670222 0.2595150 0.2194171 0.2540675\n",
    "[1] 0.2468810 0.2581577 0.2444400 0.2505256\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
